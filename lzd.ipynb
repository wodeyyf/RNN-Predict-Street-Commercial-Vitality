{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANK = ['A','B','C','D']\n",
    "NONE_RANK = 'N'\n",
    "excel_file = pd.read_excel(\"./couplet/RNN训练集.xlsx\",sheet_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the data.\n",
    "voc_dict = []\n",
    "percentage_list = []\n",
    "samples = []\n",
    "per_percnetage = 1/len(RANK)\n",
    "for i in range(len(RANK)):\n",
    "    percentage_list.append(per_percnetage*(i+1))\n",
    "\n",
    "for sheet_name,sheet_content in excel_file.items():\n",
    "    point_list = []\n",
    "    for i in range(len(percentage_list)):\n",
    "        point = sheet_content.loc[:,['评分']].quantile(percentage_list[i])\n",
    "        point_list.append(float(point))\n",
    "    \n",
    "    sample_dict = {}\n",
    "    for row in sheet_content.loc[:,['商铺顺序号','商铺类型','评分']].values:\n",
    "        if pd.isnull(row[2]):\n",
    "            continue\n",
    "        street_name = row[0][0]\n",
    "        if street_name not in sample_dict:\n",
    "            sample_dict[street_name] = [\"\",\"\"]\n",
    "        if pd.isnull(row[2]):\n",
    "            sample_dict[street_name][0] += row[1]\n",
    "            sample_dict[street_name][0] += \" \"\n",
    "            sample_dict[street_name][1] += NONE_RANK\n",
    "            sample_dict[street_name][1] += \" \"\n",
    "        else:\n",
    "            for i in range(len(point_list)):\n",
    "                if float(row[2]) <= point_list[i]:\n",
    "                    sample_dict[street_name][0] += row[1]\n",
    "                    sample_dict[street_name][0] += \" \"\n",
    "                    sample_dict[street_name][1] += RANK[i]\n",
    "                    sample_dict[street_name][1] += \" \"\n",
    "                    break\n",
    "    for sample in sample_dict.values():\n",
    "        sample[0] = sample[0][:-1].lower()\n",
    "        sample[1] = sample[1][:-1].lower()\n",
    "        samples.append(sample)\n",
    "        sample_inv = [\"\",\"\"]\n",
    "        for i in sample[0].split(\" \"):\n",
    "            voc_dict.append(i.lower())\n",
    "            sample_inv[0] = i + \" \" + sample_inv[0]\n",
    "        for i in sample[1].split(\" \"):\n",
    "            voc_dict.append(i.lower())\n",
    "            sample_inv[1] = i + \" \" + sample_inv[1]\n",
    "        sample_inv[0] = sample_inv[0][:-1].lower()\n",
    "        sample_inv[1] = sample_inv[1][:-1].lower()\n",
    "        samples.append(sample_inv)\n",
    "\n",
    "voc_dict = set(voc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ffr cfr cfr js p dh fls cs f ch sts ffr cfr ffr dh sts cfr cs cs cfr', 'a c c b a d a a d d a d b d c c c a a c']\n",
      "['cfr cs cs cfr sts dh ffr cfr ffr sts ch f cs fls dh p js cfr cfr ffr', 'c a a c c c d b d a d d a a d a b c c a']\n"
     ]
    }
   ],
   "source": [
    "print(samples[0])\n",
    "print(samples[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dh', 'h', 'f', 'ffr', 'as', 'js', 'eg', 'fls', 'con', 'd', 'sp', 'fs', 'ba', 'fis', 'sts', 'ps', 'bo', 'c', 'pcis', 'sh', 'vh', 'sa', 'cfr', 'a', 'cs', 'os', 'p', 'is', 'sps', 'tc', 'cos', 'ss', 'b', 'heh', 'hc', 'sm', 'ch', 'th'}\n"
     ]
    }
   ],
   "source": [
    "print(voc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./couplet/train/pos.txt\",encoding=\"utf-8\",mode =\"w\") as posfile,\\\n",
    "    open(f\"./couplet/train/rank.txt\",encoding=\"utf-8\",mode =\"w\") as rankfile:\n",
    "    for sample in samples:\n",
    "        posfile.write(sample[0] + \"\\n\")\n",
    "        rankfile.write(sample[1]+ \"\\n\")\n",
    "\n",
    "with open(f\"./couplet/voc\",encoding=\"utf-8\",mode =\"w\") as vocfile:\n",
    "    vocfile.write(\"<s>\\n</s>\\n,\\n。\\n\")\n",
    "    for word in voc_dict:\n",
    "        vocfile.write(word + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5', '4', '3', '2', '1']\n"
     ]
    }
   ],
   "source": [
    "test = \"1 2 3 4 5\"\n",
    "tl = []\n",
    "for i in test.split(\" \"):\n",
    "    tl.insert(0,i)\n",
    "print(tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_CHARS = ['，', '、', ',', '.', '。', '!', '！', '?', '？', ' ']\n",
    "\n",
    "\n",
    "def all_same(s):\n",
    "    if len(s) <= 1:\n",
    "        return True\n",
    "    for i in range(1, len(s)):\n",
    "        if s[i] not in SPLIT_CHARS and s[i] != s[0]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def sort_outputs(outputs, scores):\n",
    "    new_scores, new_outputs = zip(*sorted(zip(scores, outputs), reverse=True))\n",
    "    return list(new_outputs), list(new_scores)\n",
    "\n",
    "def manual_correct_result(in_str, outputs, scores):\n",
    "    is_all_same = all_same(in_str)\n",
    "    for i in range(len(outputs)):\n",
    "        if is_all_same:\n",
    "            scores[i] -= 100\n",
    "            continue\n",
    "        # print(abs(len(in_str.split(\" \")) - len(outputs[i])))\n",
    "        scores[i] -= abs(len(in_str.split(\" \")) - len(outputs[i]))*1000\n",
    "        \n",
    "    return outputs, scores\n",
    "\n",
    "def infer(in_str):\n",
    "    if len(in_str) == 0 or len(in_str) > 50:\n",
    "        return [u'您的输入太长了'], []\n",
    "    else:\n",
    "        model_outputs, model_scores = m.infer(in_str)\n",
    "        # print(model_outputs,model_scores)\n",
    "        # print(model_outputs)\n",
    "        model_scores = model_scores.tolist()\n",
    "        unsorted_outputs, unsorted_scores = manual_correct_result(in_str, model_outputs, model_scores)\n",
    "        output, score = sort_outputs(unsorted_outputs, unsorted_scores)\n",
    "        best_output = \"\"\n",
    "        for rank in output[0]:\n",
    "            best_output = best_output + rank +\" \"\n",
    "        best_output = best_output[:-1]\n",
    "\n",
    "        print('输入：%s；输出：%s ; score: %s' % (\n",
    "            in_str, best_output, score[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./output_couplet\\model.ckpl\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-25742e96150f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         restore_model=False,save_step = 5,init_infer = True)\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mg:\\code\\GitHub\\seq2seq-couplet\\model.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, epochs, start)\u001b[0m\n\u001b[0;32m    148\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_in_seq_len\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0min_seq_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_target_seq\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtarget_seq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m                             self.train_target_seq_len: target_seq_len})\n\u001b[0m\u001b[0;32m    151\u001b[0m                 \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_writter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\python\\anaconda3\\envs\\tf14\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\python\\anaconda3\\envs\\tf14\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\python\\anaconda3\\envs\\tf14\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\python\\anaconda3\\envs\\tf14\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\python\\anaconda3\\envs\\tf14\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\python\\anaconda3\\envs\\tf14\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from model import Model\n",
    "\n",
    "m = Model(\n",
    "        './couplet/train/pos.txt',##训练输入\n",
    "        './couplet/train/rank.txt',##训练输出\n",
    "        './couplet/train/pos.txt',##测试输入\n",
    "        './couplet/train/rank.txt',##测试输出，应该是空\n",
    "        './couplet/v1',\n",
    "        num_units=1024, layers=4, dropout=0.2,\n",
    "        batch_size=32, learning_rate=0.001,\n",
    "        output_dir='./output_couplet',\n",
    "        restore_model=False,save_step = 5,init_infer = True)\n",
    "\n",
    "m.train(600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "输入：cos cs ch ba sa ch ch sa cos；输出：a d b d c a d c a ; score: -0.4640083312988281\n"
     ]
    }
   ],
   "source": [
    "infer(\"cos cs ch ba sa ch ch sa cos\")\n",
    "# c a c a c d c d a c c d a a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f912d36873d220fe624911ee02ad34cf8b88bd9f8acf6e3c789a93dc6000adc"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('dsfs': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
